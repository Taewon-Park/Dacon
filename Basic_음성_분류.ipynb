{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+gqT9fv7gosLDHn7+njkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taewon-Park/Dacon/blob/main/Basic_%EC%9D%8C%EC%84%B1_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS53BiNfrRQO"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display as dsp\n",
        "from IPython.display import Audio\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "import torch\n",
        "device = torch. device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr = 22050"
      ],
      "metadata": {
        "id": "b-TzwmCjrZCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "seed_everything(813)\n",
        "\n",
        "train = pd.read_csv(base_path + '/data/train.csv')\n",
        "test = pd.read_csv(base_path + '/data/test.csv')\n",
        "submission = pd.read_csv(base_path + '/data/sample_submission.csv')"
      ],
      "metadata": {
        "id": "d01Vex3aralc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "train_file_names = train[\"file_name\"].to_numpy()\n",
        "test_file_names = test[\"file_name\"].to_numpy()\n",
        "target = train[\"label\"].to_numpy()\n",
        "\n",
        "def load_audio(file_names, target, path):\n",
        "  audios = []\n",
        "  for audio in tqdm(file_names):\n",
        "    # librosa를 이용하여 데이터 로드\n",
        "    an_audio, _ = librosa.load(path+audio, sr=sr)\n",
        "    audio_array = np.array(an_audio)\n",
        "    audios.append(audio_array)\n",
        "  audios = np.array(audios)\n",
        "\n",
        "  targets = target.copy()\n",
        "\n",
        "  return audios, targets"
      ],
      "metadata": {
        "id": "zFWB2GIlrbek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_train, target_train = load_audio(train_file_names, target, path= base_path + '/data/train/')\n",
        "audio_test, _ = load_audio(test_file_names, np.array([None]), path= base_path + '/data/test/')"
      ],
      "metadata": {
        "id": "1EtSmxgwrc-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_pad(mels, pad_size, mfcc=True):\n",
        "\n",
        "  pad_width = pad_size - mels.shape[1]\n",
        "  rand = np.random.rand()\n",
        "  left = int(pad_width * rand)\n",
        "  right = pad_width - left\n",
        "\n",
        "  if mfcc:\n",
        "    mels = np.pad(mels, pad_width=((0,0), (left, right)), mode='constant')\n",
        "    local_max, local_min = mels.max(), mels.min()\n",
        "    mels = (mels - local_min)/(local_max - local_min)\n",
        "  else:\n",
        "    local_max, local_min = mels.max(), mels.min()\n",
        "    mels = (mels - local_min)/(local_max - local_min)\n",
        "    mels = np.pad(mels, pad_width=((0,0), (left, right)), mode='constant')\n",
        "\n",
        "\n",
        "  return mels"
      ],
      "metadata": {
        "id": "DvulAfPurd1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 50\n",
        "pad_size = 50\n",
        "repeat_size = 5\n",
        "sr = 22050"
      ],
      "metadata": {
        "id": "DaSbGzmWrfed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_train[0]"
      ],
      "metadata": {
        "id": "p2qx6NsErgL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_mels = []\n",
        "audio_mfcc = []\n",
        "\n",
        "for y in audio_train:\n",
        "  mels = librosa.feature.melspectrogram(y, sr=sr, n_mels=size)\n",
        "  mels = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=size)\n",
        "\n",
        "  for i in range(repeat_size):\n",
        "    audio_mels.append(random_pad(mels, pad_size=pad_size, mfcc=False))\n",
        "    audio_mfcc.append(random_pad(mfcc, pad_size=pad_size, mfcc=True))\n",
        "\n",
        "audio_mels_array_test = []\n",
        "audio_mfcc_array_test = []\n",
        "\n",
        "for y in audio_test:\n",
        "  mels = librosa.feature.melspectrogram(y, sr=sr, n_mels=size)\n",
        "  mels = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=size)\n",
        "\n",
        "  audio_mels_array_test.append(random_pad(mels, pad_size=pad_size, mfcc=False))\n",
        "  audio_mfcc_array_test.append(random_pad(mfcc, pad_size=pad_size, mfcc=True))\n",
        "\n",
        "audio_mels_array = np.array(audio_mels, np.float64)\n",
        "audio_mfcc_array = np.array(audio_mfcc, np.float64)\n",
        "\n",
        "audio_mels_array_test = np.array(audio_mels_array_test, np.float64)\n",
        "audio_mfcc_array_test = np.array(audio_mfcc_array_test, np.float64)\n",
        "\n",
        "audio_mels_array.shape"
      ],
      "metadata": {
        "id": "b2FXUOP2rgcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "repeated_target = np.repeat(train[\"label\"].to_numpy(), repeat_size)\n",
        "repeated_target.shape"
      ],
      "metadata": {
        "id": "HGX-p0oormS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization, Input, DepthwiseConv2D, Add, LeakyReLU, ReLU\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "metadata": {
        "id": "ICLgjc3SroFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters_in, filters_out):\n",
        "    shortcut = x\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters_in, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(x)\n",
        "\n",
        "    shortcut_channel = x.shape.as_list()[0]\n",
        "\n",
        "    if shortcut_channel != filters_out:\n",
        "        shortcut = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    return ReLU()(x)"
      ],
      "metadata": {
        "id": "rJFWdsTZrpJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=(size,pad_size,1))\n",
        "\n",
        "  outputs = Conv2D(16,(3,3),activation=None,padding='same',kernel_initializer='he_normal')(inputs)\n",
        "  outputs = BatchNormalization()(outputs)\n",
        "  outputs = ReLU()(outputs)\n",
        "  outputs = MaxPool2D((2,2))(outputs)\n",
        "\n",
        "  outputs = residual_block(outputs, 16, 32)\n",
        "  outputs = MaxPool2D((2,2))(outputs)\n",
        "  outputs = residual_block(outputs, 32, 32)\n",
        "  #outputs = residual_block(outputs, 32, 32)\n",
        "  outputs = residual_block(outputs, 32, 64)\n",
        "  outputs = MaxPool2D((2,2))(outputs)\n",
        "  outputs = residual_block(outputs, 64, 64)\n",
        "  # outputs = residual_block(outputs, 64, 64)\n",
        "  outputs = MaxPool2D((2,2))(outputs)\n",
        "\n",
        "  outputs = GlobalAveragePooling2D()(outputs)\n",
        "  outputs = Flatten()(outputs)\n",
        "\n",
        "  outputs = Dense(32,activation=None,kernel_initializer='he_normal')(outputs)\n",
        "  outputs = BatchNormalization()(outputs)\n",
        "  outputs = ReLU()(outputs)\n",
        "  outputs = Dropout(0.5)(outputs)\n",
        "\n",
        "  outputs = Dense(10,activation='softmax')(outputs)\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EZqRqrZarphc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc_list = []\n",
        "pred_list = []\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for fold,(train_index, val_index) in enumerate(skf.split(audio_mels_array, repeated_target)):\n",
        "\n",
        "  print(f'\\n********** {fold+1} fold **********')\n",
        "\n",
        "  preds_val_list = []\n",
        "  ### melspectrogram ###\n",
        "  model = build_model()\n",
        "  x_train, x_val, y_train, y_val = audio_mels_array[train_index], audio_mels_array[val_index], repeated_target[train_index], repeated_target[val_index]\n",
        "  filepath = f\"model.res_test_0615_mels_{fold}.hdf5\"\n",
        "  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')]\n",
        "  history = model.fit(x_train, y_train, batch_size=32, epochs=50, validation_data=(x_val,y_val), callbacks=callbacks, verbose=0)\n",
        "  model = load_model(filepath)\n",
        "\n",
        "  preds_val = model.predict(x_val)\n",
        "  preds_val_list.append(preds_val)\n",
        "  preds_val_label = np.argmax(preds_val, axis=1)\n",
        "  pred_list.append(model.predict(audio_mels_array_test))\n",
        "  print(f'mels_model_acc : {accuracy_score(y_val,preds_val_label):.4f}')\n",
        "\n",
        "  ### mfcc ###\n",
        "  model = build_model()\n",
        "  x_train, x_val, y_train, y_val = audio_mfcc_array[train_index], audio_mfcc_array[val_index], repeated_target[train_index], repeated_target[val_index]\n",
        "  filepath = f\"model.res_test_0615_mfcc_{fold}.hdf5\"\n",
        "  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')]\n",
        "  history = model.fit(x_train, y_train, batch_size=32, epochs=50, validation_data=(x_val,y_val), callbacks=callbacks, verbose=0)\n",
        "  model = load_model(filepath)\n",
        "\n",
        "  preds_val = model.predict(x_val)\n",
        "  preds_val_list.append(preds_val)\n",
        "  preds_val_label = np.argmax(preds_val, axis=1)\n",
        "  pred_list.append(model.predict(audio_mfcc_array_test))\n",
        "  print(f'mfcc_model_acc : {accuracy_score(y_val,preds_val_label):.4f}')\n",
        "\n",
        "  ### ensemble ###\n",
        "  val_pred_result = preds_val_list[0].copy()\n",
        "  for i in range(1, len(preds_val_list)):\n",
        "      val_pred_result += preds_val_list[i]\n",
        "  val_pred_label = np.argmax(val_pred_result, axis=1)\n",
        "  en_acc = accuracy_score(y_val,val_pred_label)\n",
        "  acc_list.append(en_acc)\n",
        "  print(f'ensemble_model_acc : {en_acc:.4f}')\n",
        "\n",
        "print(f'\\n\\nmean_acc : {np.mean(acc_list):.4f}')"
      ],
      "metadata": {
        "id": "gdeIUSi0rrfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_result = pred_list[0].copy()\n",
        "for i in range(1, len(pred_list)):\n",
        "    test_pred_result += pred_list[i]\n",
        "\n",
        "submission['label'] = np.argmax(test_pred_result, axis=1)\n",
        "submission.head()\n",
        "submission.to_csv( base_path + '/data/saved/CNN001.csv', index=False)"
      ],
      "metadata": {
        "id": "-z5q9gUJrsR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}