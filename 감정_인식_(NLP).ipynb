{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5/HB3I+plFiV0VgHm6uG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taewon-Park/Dacon/blob/main/%EA%B0%90%EC%A0%95_%EC%9D%B8%EC%8B%9D_(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmoFh8I6qql5",
        "outputId": "5b05045b-5b4c-4533-8393-734ce45ecefb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dacon/발화자의 감정인식/data/open')"
      ],
      "metadata": {
        "id": "QtmV9-6RrN3r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?=1-QNs8sk5X3u_1rK-dv5ESgQIt0ZDQSwY\n",
        "!unzip -qq \"./data/databffhw4rntmp\""
      ],
      "metadata": {
        "id": "eRYkr9TTxOb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requirements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, RobertaModel, AutoModel\n",
        "from transformers import BertModel, RobertaTokenizer, AutoTokenizer\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "N_74q1SuquLn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data Load\n",
        "data = pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "rOVANQ8ZrUED"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz0JvXECrmQX",
        "outputId": "c83517d4-0f70-43dd-85b5-56ad23af237b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9989 entries, 0 to 9988\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   ID           9989 non-null   object\n",
            " 1   Utterance    9989 non-null   object\n",
            " 2   Speaker      9989 non-null   object\n",
            " 3   Dialogue_ID  9989 non-null   int64 \n",
            " 4   Target       9989 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 390.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:5000]"
      ],
      "metadata": {
        "id": "xQFJbB1vrqSW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbjnNvs0rrwT",
        "outputId": "c1f0d666-e523-4800-b375-a849574db5f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   ID           5000 non-null   object\n",
            " 1   Utterance    5000 non-null   object\n",
            " 2   Speaker      5000 non-null   object\n",
            " 3   Dialogue_ID  5000 non-null   int64 \n",
            " 4   Target       5000 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 195.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "CFG = {\n",
        "  'EPOCHS' : 50,\n",
        "  'LEARNING_RATE' : 1e-5,\n",
        "  'BATCH_SIZE' : 2,\n",
        "  'SEED' : 42\n",
        "}\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def Encoding(data):\n",
        "  le = LabelEncoder()\n",
        "  le = le.fit(data['Target'])\n",
        "  data['Target'] = le.transform(data['Target'])\n",
        "\n",
        "  return data['Target']\n",
        "\n",
        "def Class_Weights(data):\n",
        "  class_counts = data['Target'].value_counts()\n",
        "  class_weights = 1./class_counts\n",
        "  class_weights = class_weights/class_weights.min()\n",
        "  class_weights = class_weights.to_dict()\n",
        "  class_weights = {k : v for k, v in sorted(class_weights.items(), key=lambda item : item[0])}\n",
        "  class_weights = list(class_weights.values())\n",
        "  class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "  return class_weights\n",
        "\n",
        "def Strat_Split(nsplit, data):\n",
        "\n",
        "  folds = StratifiedKFold(n_splits=nsplit, shuffle=True, random_state=CFG['SEED'])\n",
        "  data['fold'] = -1\n",
        "  for i in range(nsplit):\n",
        "    trn_idx, val_idx = list(folds.split(data, data['Target']))[i]\n",
        "    valid = data.iloc[val_idx]\n",
        "    data.loc[data[data.ID.isin(valid.ID) == True].index.to_list(), 'fold'] = i\n",
        "\n",
        "  data.to_csv('train_fold.csv', index=False)\n",
        "  fold = pd.read_csv(\"train_fold.csv\")\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  le = le.fit(fold['Target'])\n",
        "  fold['Target'] = le.transform(fold['Target'])\n",
        "\n",
        "  strat_train = fold[fold['fold'] != 1].reset_index(drop=True)\n",
        "  strat_valid = fold[fold['fold'] == 1].reset_index(drop=True)\n",
        "\n",
        "  return strat_train, strat_valid, le\n",
        "\n",
        "\n",
        "def Tokenizer_Define():\n",
        "  bert = AutoModel.from_pretrained(\"tae898/emoberta-large\").to(device)\n",
        "  bert_pool = bert.pooler\n",
        "  bert.pooler = torch.nn.Identity()\n",
        "\n",
        "  return bert, bert_pool\n",
        "\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data, mode = \"train\"):\n",
        "    self.dataset = data\n",
        "    self.mode = mode\n",
        "    self.feature = []\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"tae898/emoberta-large\")\n",
        "\n",
        "    for text in tqdm(data['Utterance']):\n",
        "      inputs = tokenizer(text, padding='max_length', max_length=328, truncation=True, return_tensors=\"pt\")\n",
        "      input_ids = inputs['input_ids'][0][None].to(device)\n",
        "      attention_mask = inputs['attention_mask'][0][None].to(device)\n",
        "\n",
        "      _, pooled_output = bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "      self.feature.append(pooled_output.detach()[0])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.mode == \"train\":\n",
        "      return self.feature[idx], self.dataset['Target'][idx]\n",
        "    else:\n",
        "      return self.feature[idx]"
      ],
      "metadata": {
        "id": "rWNhAQQ7rBxp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Preprocessing\n",
        "seed_everything(CFG['SEED'])\n",
        "\n",
        "Encoding(data)\n",
        "class_weights = Class_Weights(data)\n",
        "strat_train, strat_valid, le = Strat_Split(35, data)\n",
        "\n",
        "bert, bert_pool = Tokenizer_Define()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKIu1EX7rtnS",
        "outputId": "c0ce00a0-dbc1-4ca8-e48f-4d307b7543bc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at tae898/emoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified Dataset Check\n",
        "print(\"train set : \", len(strat_train))\n",
        "print(\"test set : \", len(strat_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZQQvpulsm0l",
        "outputId": "c467ef5c-ad45-47f0-bb70-3650c2e6a63e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set :  4857\n",
            "test set :  143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make CustomDataset & DataLoader\n",
        "train_ds = CustomDataset(strat_train, mode = \"train\")\n",
        "valid_ds = CustomDataset(strat_valid, mode = \"train\")\n",
        "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size= CFG['BATCH_SIZE'], shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(valid_ds, batch_size= CFG['BATCH_SIZE'], shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc5poDGAtUEl",
        "outputId": "7cf5a58c-ff4b-4b1e-e779-a5d86ce51a21"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4857/4857 [06:23<00:00, 12.67it/s]\n",
            "100%|██████████| 143/143 [00:10<00:00, 13.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeling\n",
        "class BaseModel(nn.Module):\n",
        "  def __init__(self, dropout=0.5, num_classes=len(le.classes_)):\n",
        "    super(BaseModel, self).__init__()\n",
        "    self.bert_pool = bert_pool\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear = nn.Sequential(\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, pooled_output):\n",
        "    pooled_output = self.bert_pool(pooled_output)\n",
        "    dropout_output = self.dropout(pooled_output)\n",
        "    linear_output = self.linear(pooled_output)\n",
        "\n",
        "    return linear_output\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_loader, test_loader, scheduler, class_weights, device):\n",
        "  model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
        "\n",
        "  best_score = 0\n",
        "  best_model = \"None\"\n",
        "  for epoch_num in range(CFG[\"EPOCHS\"]):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    for pooled_output, train_label in tqdm(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      pooled_output = pooled_output.to(device)\n",
        "      train_label = train_label.to(device)\n",
        "\n",
        "      output = model(pooled_output).to(device)\n",
        "      batch_loss = criterion(output, train_label.long())\n",
        "\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(batch_loss.item())\n",
        "\n",
        "    val_loss, val_score = validation(model, criterion, test_loader, device)\n",
        "    print(f'Epoch [{epoch_num}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score : .5f}]')\n",
        "    if scheduler is not None:\n",
        "      scheduler.step(val_score)\n",
        "\n",
        "    best_model = model\n",
        "    best_score = val_score\n",
        "\n",
        "  return best_model\n",
        "\n",
        "\n",
        "def competition_metric(true, pred):\n",
        "  return f1_score(true, pred, average=\"macro\")\n",
        "\n",
        "\n",
        "def validation(model, criterion, test_loader, device):\n",
        "  model.eval()\n",
        "\n",
        "  val_loss = []\n",
        "  model_preds = []\n",
        "  true_labels = []\n",
        "  with torch.no_grad():\n",
        "    for pooled_output, valid_label in tqdm(test_loader):\n",
        "      valid_label = valid_label.to(device)\n",
        "      pooled_output = pooled_output.to(device)\n",
        "\n",
        "      output = model(pooled_output).to(device)\n",
        "\n",
        "      batch_loss = criterion(output, valid_label.long())\n",
        "      val_loss.append(batch_loss.item())\n",
        "\n",
        "      model_preds += output.argmax(1).detach().cpu().numpy().tolist()\n",
        "      true_labels += valid_label.detach().cpu().numpy().tolist()\n",
        "      val_f1 = competition_metric(true_labels, model_preds)\n",
        "\n",
        "  return val_loss, val_f1"
      ],
      "metadata": {
        "id": "oXqbtbtPrE3n"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
        "infer_model = train(model, optimizer, train_dataloader, val_dataloader, scheduler, class_weights, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxeY8zCWvonj",
        "outputId": "269c9249-ca5d-4c6d-a9ef-49dc76f20733"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 304.74it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 456.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], Train Loss : [0.91105] Val Loss : [0.99467] Val F1 Score : [ 0.61517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 322.07it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 159.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Train Loss : [0.74238] Val Loss : [0.85119] Val F1 Score : [ 0.65599]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:10<00:00, 239.82it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 303.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], Train Loss : [0.70954] Val Loss : [0.88904] Val F1 Score : [ 0.61767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 411.98it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 350.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], Train Loss : [0.68084] Val Loss : [0.94985] Val F1 Score : [ 0.61752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 405.40it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 463.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], Train Loss : [0.66953] Val Loss : [0.88827] Val F1 Score : [ 0.63861]\n",
            "Epoch 00005: reducing learning rate of group 0 to 5.0000e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 433.99it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 316.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], Train Loss : [0.64093] Val Loss : [0.91349] Val F1 Score : [ 0.62272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:11<00:00, 209.06it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 316.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6], Train Loss : [0.63210] Val Loss : [0.88437] Val F1 Score : [ 0.64420]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 259.49it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 143.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7], Train Loss : [0.62035] Val Loss : [0.91609] Val F1 Score : [ 0.65938]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 268.19it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 322.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8], Train Loss : [0.60353] Val Loss : [0.91702] Val F1 Score : [ 0.64168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:11<00:00, 216.32it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 180.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9], Train Loss : [0.60144] Val Loss : [0.90097] Val F1 Score : [ 0.58640]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 250.02it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 331.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10], Train Loss : [0.59207] Val Loss : [0.86793] Val F1 Score : [ 0.61846]\n",
            "Epoch 00011: reducing learning rate of group 0 to 2.5000e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 271.54it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 120.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11], Train Loss : [0.56905] Val Loss : [0.88913] Val F1 Score : [ 0.62569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 275.41it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 316.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12], Train Loss : [0.56701] Val Loss : [0.93903] Val F1 Score : [ 0.62569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 264.75it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 169.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13], Train Loss : [0.56289] Val Loss : [0.95303] Val F1 Score : [ 0.66021]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 259.59it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 202.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14], Train Loss : [0.56128] Val Loss : [0.90480] Val F1 Score : [ 0.62899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:11<00:00, 203.67it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 322.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15], Train Loss : [0.54613] Val Loss : [0.95218] Val F1 Score : [ 0.67526]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 329.68it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 311.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16], Train Loss : [0.54628] Val Loss : [0.95845] Val F1 Score : [ 0.59725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:12<00:00, 198.45it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 184.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17], Train Loss : [0.53263] Val Loss : [0.95033] Val F1 Score : [ 0.59202]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 247.57it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 339.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18], Train Loss : [0.54043] Val Loss : [0.84679] Val F1 Score : [ 0.58872]\n",
            "Epoch 00019: reducing learning rate of group 0 to 1.2500e-06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 419.80it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 456.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19], Train Loss : [0.52697] Val Loss : [0.90363] Val F1 Score : [ 0.58872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 368.33it/s]\n",
            "100%|██████████| 72/72 [00:01<00:00, 68.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], Train Loss : [0.52275] Val Loss : [0.90925] Val F1 Score : [ 0.58872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 283.93it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 318.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21], Train Loss : [0.52295] Val Loss : [0.97620] Val F1 Score : [ 0.58872]\n",
            "Epoch 00022: reducing learning rate of group 0 to 6.2500e-07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 375.57it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 489.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22], Train Loss : [0.51306] Val Loss : [0.91967] Val F1 Score : [ 0.58872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 315.52it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 278.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23], Train Loss : [0.51281] Val Loss : [0.98925] Val F1 Score : [ 0.62379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 298.78it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 312.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24], Train Loss : [0.51131] Val Loss : [0.98219] Val F1 Score : [ 0.62775]\n",
            "Epoch 00025: reducing learning rate of group 0 to 3.1250e-07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 286.35it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 461.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25], Train Loss : [0.51211] Val Loss : [0.95027] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 330.01it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 322.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26], Train Loss : [0.51501] Val Loss : [0.92880] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:08<00:00, 271.18it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 314.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27], Train Loss : [0.51385] Val Loss : [1.01221] Val F1 Score : [ 0.62775]\n",
            "Epoch 00028: reducing learning rate of group 0 to 1.5625e-07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 364.03it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 305.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28], Train Loss : [0.50565] Val Loss : [0.96253] Val F1 Score : [ 0.58872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:12<00:00, 201.32it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 324.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29], Train Loss : [0.50540] Val Loss : [0.85654] Val F1 Score : [ 0.58872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 382.15it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 311.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30], Train Loss : [0.51490] Val Loss : [1.00427] Val F1 Score : [ 0.58872]\n",
            "Epoch 00031: reducing learning rate of group 0 to 7.8125e-08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 372.36it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 350.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31], Train Loss : [0.51636] Val Loss : [0.89492] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 435.08it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 457.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32], Train Loss : [0.51801] Val Loss : [0.96422] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 451.33it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 470.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33], Train Loss : [0.50706] Val Loss : [0.85359] Val F1 Score : [ 0.62775]\n",
            "Epoch 00034: reducing learning rate of group 0 to 3.9063e-08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 384.62it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 297.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34], Train Loss : [0.50382] Val Loss : [0.91670] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 450.69it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 469.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35], Train Loss : [0.51199] Val Loss : [0.89988] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:05<00:00, 432.63it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 338.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36], Train Loss : [0.51014] Val Loss : [0.96095] Val F1 Score : [ 0.62775]\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.9531e-08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 395.76it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 499.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37], Train Loss : [0.50259] Val Loss : [0.92565] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 319.67it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 328.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38], Train Loss : [0.51392] Val Loss : [0.93822] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 253.19it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 222.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39], Train Loss : [0.51109] Val Loss : [0.92674] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:10<00:00, 224.92it/s]\n",
            "100%|██████████| 72/72 [00:01<00:00, 62.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40], Train Loss : [0.51090] Val Loss : [0.94170] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 245.82it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 296.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41], Train Loss : [0.50604] Val Loss : [0.98902] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 309.46it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 192.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42], Train Loss : [0.50729] Val Loss : [0.86990] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 312.38it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 297.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43], Train Loss : [0.50713] Val Loss : [0.95339] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 322.73it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 107.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44], Train Loss : [0.50623] Val Loss : [0.95333] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:11<00:00, 203.86it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 150.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45], Train Loss : [0.50956] Val Loss : [0.89178] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 253.41it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 242.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46], Train Loss : [0.50860] Val Loss : [0.96644] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:06<00:00, 352.54it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 312.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47], Train Loss : [0.50745] Val Loss : [0.87630] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:09<00:00, 259.73it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 248.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48], Train Loss : [0.50846] Val Loss : [0.95146] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2429/2429 [00:07<00:00, 318.69it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 312.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49], Train Loss : [0.50583] Val Loss : [0.94158] Val F1 Score : [ 0.62775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "0g5e8T8G0BYe"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(infer_model.state_dict(), 'infer_model.pt')"
      ],
      "metadata": {
        "id": "CuMabEPgzCT9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ESn84KG2ysK1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data Load\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test = test[:1000]\n",
        "\n",
        "test_ds = CustomDataset(test, mode = \"test\")\n",
        "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "aE-HWEnowkcI",
        "outputId": "920286b2-f6cc-4592-c9e1-5a973e31a66c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 366/1000 [00:28<00:50, 12.66it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2b4d48b3f01f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BATCH_SIZE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-689fc79ad812>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         )\n\u001b[0;32m--> 835\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 )\n\u001b[1;32m    523\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    525\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 340\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 6.81 MiB is free. Process 2116 has 14.74 GiB memory in use. Of the allocated memory 13.81 GiB is allocated by PyTorch, and 95.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_predict = []\n",
        "    for pooled_output in tqdm(test_loader):\n",
        "        pooled_output = pooled_output.to(device)\n",
        "        y_pred = model(pooled_output)\n",
        "        test_predict += y_pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "    print('Done.')\n",
        "\n",
        "    return test_predict"
      ],
      "metadata": {
        "id": "DwoVx9ILwP6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = inference(infer_model, test_dataloader, device)\n",
        "preds = le.inverse_transfrom(preds)\n",
        "\n",
        "submit = pd.read_csv('sample_submission.csv')\n",
        "submit['Target'] = preds\n",
        "\n",
        "# submit에서 Target이 0이면 anger로 변환\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'anger' if x == 0 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'disgust' if x == 1 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'fear' if x == 2 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'joy' if x == 3 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'neutral' if x == 4 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'sadness' if x == 5 else x)\n",
        "submit['Target'] = submit['Target'].apply(lambda x: 'surprise' if x == 6 else x)\n",
        "\n",
        "submit.to_csv('submit.csv', index=False)"
      ],
      "metadata": {
        "id": "tUD-NAVaw5Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ssRdvYV7ySvC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}