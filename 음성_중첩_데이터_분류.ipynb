{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWLJDXsaOM/wswVp6CeUP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taewon-Park/Dacon/blob/main/%EC%9D%8C%EC%84%B1_%EC%A4%91%EC%B2%A9_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1LN3A6oXgv-uapNxyilKy3V0z3sRW8TON"
      ],
      "metadata": {
        "id": "__K8OSeOrAy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unizp 235616_음성 중첩 데이터 분류 AI 경진대회_data.zip"
      ],
      "metadata": {
        "id": "fGFjvDh2rGNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yuyH7T5ikwq"
      },
      "outputs": [],
      "source": [
        "# 라이브러리\n",
        "import random\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchaudio.transforms as AT\n",
        "from torch import nn, optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed 및 GPU 설정\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "YS-BLvRRiqdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature 생성\n",
        "class MRMS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MRMS, self).__init__()\n",
        "        self.sr, self.n_fft, self.hop, self.pad, self.f_min, self.f_max, self.n_mels = \\\n",
        "            16000, 2048, 100, 50, 25, 7500, 160\n",
        "        self.tf_0 = self.create_tf(250)\n",
        "        self.tf_1 = self.create_tf(500)\n",
        "        self.tf_2 = self.create_tf(750)\n",
        "        self.tf_3 = self.create_tf(1000)\n",
        "        self.cali = torch.linspace(-0.5, 0.5, steps=160, device=DEVICE).view(1, -1, 1)\n",
        "\n",
        "    def create_tf(self, win_length):\n",
        "        tf = nn.Sequential(\n",
        "            AT.MelSpectrogram(sample_rate=self.sr,\n",
        "                              n_fft=self.n_fft,\n",
        "                              win_length=win_length,\n",
        "                              hop_length=self.hop,\n",
        "                              pad=self.pad,\n",
        "                              f_min=self.f_min,\n",
        "                              f_max=self.f_max,\n",
        "                              n_mels=self.n_mels),\n",
        "            AT.AmplitudeToDB()\n",
        "        )\n",
        "        return tf\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            spec_0 = self.tf_0(x)[0, :, 1:-1]\n",
        "            spec_1 = self.tf_1(x)[0, :, 1:-1]\n",
        "            spec_2 = self.tf_2(x)[0, :, 1:-1]\n",
        "            spec_3 = self.tf_3(x)[0, :, 1:-1]\n",
        "            out = torch.stack([spec_0, spec_1, spec_2, spec_3], dim=0)\n",
        "            out = (out - out.mean(dim=[1, 2], keepdim=True)) / 20 + self.cali\n",
        "            return out\n",
        "\n",
        "extractor = MRMS().to(DEVICE)"
      ],
      "metadata": {
        "id": "Wp-MyLoPixAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(np.sort(glob('./Data/train/*.wav'))):\n",
        "    x, _ = torchaudio.load(file_name)\n",
        "    x = x.to(DEVICE)\n",
        "    spec = extractor(x)\n",
        "    name = './Cache/train/' + file_name.split('/')[-1].split('.')[0] + '.pt'\n",
        "    torch.save(spec.to('cpu'), name)\n",
        "\n",
        "for file_name in tqdm(np.sort(glob('./Data/test/*.wav'))):\n",
        "    x, _ = torchaudio.load(file_name)\n",
        "    x = x.to(DEVICE)\n",
        "    spec = extractor(x)\n",
        "    name = './Cache/test/' + file_name.split('/')[-1].split('.')[0] + '.pt'\n",
        "    torch.save(spec.to('cpu'), name)"
      ],
      "metadata": {
        "id": "sBuA4iNDmkJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 Augmentation\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_list, gt_list, augmentation):\n",
        "        self.file_list = file_list\n",
        "        self.gt_list = gt_list\n",
        "        self.augmentation = augmentation\n",
        "        self.spec_augment = nn.Sequential(\n",
        "            AT.FrequencyMasking(32, False),\n",
        "            AT.TimeMasking(12, False),\n",
        "            AT.TimeMasking(12, False),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with torch.no_grad():\n",
        "            x = torch.load(self.file_list[index])\n",
        "            gt = self.gt_list[index]\n",
        "\n",
        "            if self.augmentation:\n",
        "                x = self.spec_augment(x)\n",
        "                i, j = random.randrange(64), random.randrange(64)\n",
        "                x = F.pad(x, [32, 32, 32, 32])\n",
        "                x = x[:, i:i + 160, j:j + 160]\n",
        "\n",
        "                if random.random() > 0.25:\n",
        "                    mixup_lambda = random.uniform(0.05, 0.25)\n",
        "                    mixup_index = random.randrange(self.__len__())\n",
        "                    mixup_x = torch.load(self.file_list[mixup_index])\n",
        "                    mixup_gt = self.gt_list[mixup_index]\n",
        "                    x = (1 - mixup_lambda) * x + mixup_lambda * mixup_x\n",
        "                    gt = (1 - mixup_lambda) * gt + mixup_lambda * mixup_gt\n",
        "            return x, gt"
      ],
      "metadata": {
        "id": "ns5sA8prmlRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 파라미터\n",
        "N_MODEL = 16\n",
        "N_EPOCH = 200\n",
        "BATCH_SIZE = 128\n",
        "MODEL_FACTOR = 24\n",
        "LEARNING_RATE = 0.2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0001\n",
        "LOADER_PARAM = {\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'num_workers': 3,\n",
        "    'pin_memory': True\n",
        "}"
      ],
      "metadata": {
        "id": "EdnzcaQGmoMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "train_x = np.sort(glob('./Cache/train/*.pt'))\n",
        "test_x = np.sort(glob('./Cache/test/*.pt'))\n",
        "train_y = torch.tensor(pd.read_csv('./Data/train_answer.csv')\n",
        "                       .to_numpy()[:, 1:], dtype=torch.float32)\n",
        "\n",
        "train_loader = DataLoader(CustomDataset(train_x, train_y, augmentation=True),\n",
        "                          shuffle=True, drop_last=True, **LOADER_PARAM)\n",
        "test_loader = DataLoader(CustomDataset(test_x, list(range(10000)), augmentation=False),\n",
        "                         shuffle=False, drop_last=False, **LOADER_PARAM)"
      ],
      "metadata": {
        "id": "AIVEtpeAmq6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델\n",
        "class bn_relu_conv(nn.Module):\n",
        "\n",
        "    def __init__(self, ks, n_in, n_out):\n",
        "        super(bn_relu_conv, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(n_in)\n",
        "        self.relu = nn.LeakyReLU(0.1)\n",
        "        self.conv = nn.Conv2d(n_in, n_out, kernel_size=ks, padding=ks // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(self.relu(self.bn(x)))\n",
        "\n",
        "\n",
        "class MAC(nn.Module):\n",
        "\n",
        "    def __init__(self, pool_method):\n",
        "        super(MAC, self).__init__()\n",
        "        self.factor = MODEL_FACTOR\n",
        "        self.pool = nn.AvgPool2d(2) if pool_method == 'Avg' else nn.MaxPool2d(2)\n",
        "        self.initialize = nn.Conv2d(4, 2 * self.factor, 6, stride=2, padding=2)\n",
        "        self.lg_0 = nn.Sequential(\n",
        "            bn_relu_conv(1, 2 * self.factor, self.factor),\n",
        "            bn_relu_conv(3, self.factor, self.factor),\n",
        "            bn_relu_conv(1, self.factor, self.factor),\n",
        "            bn_relu_conv(3, self.factor, self.factor)\n",
        "        )\n",
        "        self.lg_1 = nn.Sequential(\n",
        "            bn_relu_conv(1, self.factor, 2 * self.factor),\n",
        "            bn_relu_conv(3, 2 * self.factor, 2 * self.factor),\n",
        "            bn_relu_conv(1, 2 * self.factor, 2 * self.factor),\n",
        "            bn_relu_conv(3, 2 * self.factor, 2 * self.factor)\n",
        "        )\n",
        "        self.lg_2 = nn.Sequential(\n",
        "            bn_relu_conv(1, 2 * self.factor, 4 * self.factor),\n",
        "            bn_relu_conv(3, 4 * self.factor, 4 * self.factor),\n",
        "            bn_relu_conv(1, 4 * self.factor, 4 * self.factor),\n",
        "            bn_relu_conv(3, 4 * self.factor, 4 * self.factor)\n",
        "        )\n",
        "        self.lg_3 = nn.Sequential(\n",
        "            bn_relu_conv(1, 4 * self.factor, 6 * self.factor),\n",
        "            bn_relu_conv(3, 6 * self.factor, 6 * self.factor),\n",
        "            bn_relu_conv(1, 6 * self.factor, 6 * self.factor),\n",
        "            bn_relu_conv(3, 6 * self.factor, 6 * self.factor)\n",
        "        )\n",
        "        self.lg_4 = nn.Sequential(\n",
        "            bn_relu_conv(1, 6 * self.factor, 8 * self.factor),\n",
        "            bn_relu_conv(3, 8 * self.factor, 8 * self.factor),\n",
        "            bn_relu_conv(1, 8 * self.factor, 8 * self.factor),\n",
        "            bn_relu_conv(3, 8 * self.factor, 8 * self.factor)\n",
        "        )\n",
        "        self.finalize = nn.Sequential(\n",
        "            bn_relu_conv(1, 8 * self.factor, 16 * self.factor),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        ) if pool_method == 'Avg' else nn.Sequential(\n",
        "            bn_relu_conv(1, 8 * self.factor, 16 * self.factor),\n",
        "            nn.AdaptiveMaxPool2d(1)\n",
        "        )\n",
        "\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(16 * self.factor, 8 * self.factor),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.BatchNorm1d(8 * self.factor),\n",
        "            nn.LeakyReLU(0.25),\n",
        "            nn.Linear(8 * self.factor, 30)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initialize(x)\n",
        "        x = self.pool(self.lg_0(x))\n",
        "        x = self.pool(self.lg_1(x))\n",
        "        x = self.pool(self.lg_2(x))\n",
        "        x = self.pool(self.lg_3(x))\n",
        "        x = self.finalize(self.lg_4(x))\n",
        "        x = self.dense(x.view(x.shape[0], -1))\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "f85TyWWXms8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Method\n",
        "def train(model_no, pool_method):\n",
        "    model = MAC(pool_method).to(DEVICE)\n",
        "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
        "                          momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=N_EPOCH, eta_min=LEARNING_RATE / 40)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(N_EPOCH):\n",
        "        model.train()\n",
        "        running_loss, running_count = 0., 0\n",
        "\n",
        "        for i, (xx, yy) in tqdm(enumerate(train_loader), leave=False):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
        "                pred = model(xx)\n",
        "                loss = criterion(pred, yy)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step(epoch + i / len(train_loader))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                running_loss += loss.item() * len(yy)\n",
        "                running_count += len(yy)\n",
        "\n",
        "        print('{}Pool Model {:01d} Epoch {:03d} | Train {:7.5f}'\n",
        "              .format(pool_method, model_no + 1, epoch + 1, running_loss / running_count))\n",
        "\n",
        "    model.eval()\n",
        "    prediction = torch.zeros((10000, 30), dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (xx, _) in enumerate(test_loader):\n",
        "            xx = xx.to(DEVICE)\n",
        "            pred = model(xx).detach().exp().to('cpu')\n",
        "            prediction[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction))] = pred[:, :]\n",
        "\n",
        "    df = pd.read_csv('./Data/submission.csv')\n",
        "    df.iloc[:, 1:] = prediction.numpy()\n",
        "    df.to_csv('./SubResult/{}{:01d}.csv'.format(pool_method, model_no + 1), index=False)"
      ],
      "metadata": {
        "id": "C6aiuyKUmuz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "for m in range(N_MODEL // 2):\n",
        "    train(m, 'Avg')\n",
        "    train(m, 'Max')\n",
        "\n",
        "out = np.zeros((10000, 30), dtype=np.float32)\n",
        "file_list = glob('./SubResult/*.csv')\n",
        "\n",
        "for file_name in file_list:\n",
        "    print(file_name)\n",
        "    out += pd.read_csv(file_name).to_numpy()[:, 1:]\n",
        "out /= len(file_list)\n",
        "\n",
        "df = pd.read_csv('./Data/submission.csv')\n",
        "df.iloc[:, 1:] = out\n",
        "df.to_csv('./PredictionFinal.csv', index=False)"
      ],
      "metadata": {
        "id": "G1cmLffamyIG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}